{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "848a57cd",
   "metadata": {},
   "source": [
    "# Ensemble Technique\n",
    "whenever we have huge data set so it is not posible to learn huge data set with 1 module so we will devide into small chunck of code like subset 1 sebse 2 like this creat subsets from the huge data set then those subsets providce to the module to learn and test then module return accuracy of those subsets and find out the mean score of accuracy of all subsets so these are done with the help of ensemble method\n",
    "Ensemble technique is 2 types\n",
    "1.Bagging (it is use for the prellel with data module or differentr algo).\n",
    "for bagging use Random forest algorithm inside that we call Decision tree  \n",
    "2.Boosting (it is use for the sequential with the module). \n",
    "for boosting used gradient and adaboost algorithm or extra tree are these are boosting algo for sequential purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fa31d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#naive bayes classifier algo\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# for logistic Regression metrics for binary data\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "# for Linear regression metrics\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error,r2_score\n",
    "\n",
    "\n",
    "#its Ensemble bagging algo\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "#ensem,ble Bossting algo\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "#ensemble Voting classifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10d78d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaa75170",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris=load_iris()\n",
    "x=iris.data[:,:4]\n",
    "y=iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d35891ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=.33,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7506f3be",
   "metadata": {},
   "source": [
    "# Bagging (algo-Random Forest and Extra Tree Classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94931718",
   "metadata": {},
   "outputs": [],
   "source": [
    "#base_estimator not change for bagging\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dec3a7d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98\n",
      "[[19  0  0]\n",
      " [ 0 15  0]\n",
      " [ 0  1 15]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       0.94      1.00      0.97        15\n",
      "           2       1.00      0.94      0.97        16\n",
      "\n",
      "    accuracy                           0.98        50\n",
      "   macro avg       0.98      0.98      0.98        50\n",
      "weighted avg       0.98      0.98      0.98        50\n",
      "\n",
      "\n",
      "\n",
      "0.98\n",
      "[[19  0  0]\n",
      " [ 0 15  0]\n",
      " [ 0  1 15]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       0.94      1.00      0.97        15\n",
      "           2       1.00      0.94      0.97        16\n",
      "\n",
      "    accuracy                           0.98        50\n",
      "   macro avg       0.98      0.98      0.98        50\n",
      "weighted avg       0.98      0.98      0.98        50\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf=RandomForestClassifier(n_estimators=100,random_state=42)\n",
    "# here estimator indicate 100 subsets\n",
    "rf.fit(x_train,y_train)\n",
    "predrf=rf.predict(x_test)\n",
    "print(accuracy_score(y_test,predrf))\n",
    "print(confusion_matrix(y_test,predrf))\n",
    "print(classification_report(y_test,predrf))\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "\n",
    "# here we can take ExtraTreeClassifier Algo also\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "et=ExtraTreesClassifier(n_estimators=100,random_state=42)\n",
    "et=ExtraTreesClassifier()\n",
    "et.fit(x_train,y_train)\n",
    "predet=et.predict(x_test)\n",
    "print(accuracy_score(y_test,predet))\n",
    "print(confusion_matrix(y_test,predet))\n",
    "print(classification_report(y_test,predet))\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd1bfc1",
   "metadata": {},
   "source": [
    "# Boosting (Algo- AdaBoost and GredientBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4900b9e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98\n",
      "[[19  0  0]\n",
      " [ 0 15  0]\n",
      " [ 0  1 15]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       0.94      1.00      0.97        15\n",
      "           2       1.00      0.94      0.97        16\n",
      "\n",
      "    accuracy                           0.98        50\n",
      "   macro avg       0.98      0.98      0.98        50\n",
      "weighted avg       0.98      0.98      0.98        50\n",
      "\n",
      "0.98\n",
      "[[19  0  0]\n",
      " [ 0 15  0]\n",
      " [ 0  1 15]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       0.94      1.00      0.97        15\n",
      "           2       1.00      0.94      0.97        16\n",
      "\n",
      "    accuracy                           0.98        50\n",
      "   macro avg       0.98      0.98      0.98        50\n",
      "weighted avg       0.98      0.98      0.98        50\n",
      "\n",
      "0.98\n",
      "[[19  0  0]\n",
      " [ 0 15  0]\n",
      " [ 0  1 15]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       0.94      1.00      0.97        15\n",
      "           2       1.00      0.94      0.97        16\n",
      "\n",
      "    accuracy                           0.98        50\n",
      "   macro avg       0.98      0.98      0.98        50\n",
      "weighted avg       0.98      0.98      0.98        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ad=AdaBoostClassifier(base_estimator=DecisionTreeClassifier(),n_estimators=150,learning_rate=1.0)\n",
    "ad=AdaBoostClassifier()\n",
    "ad.fit(x_train,y_train)\n",
    "predad=et.predict(x_test)\n",
    "print(accuracy_score(y_test,predad))\n",
    "print(confusion_matrix(y_test,predad))\n",
    "print(classification_report(y_test,predad))\n",
    "\n",
    "#we can change baseestimator also\n",
    "svc=SVC()\n",
    "#here ('rbf')its type to need ('SAMME')\n",
    "#here if we pass \"Linear\" then use it take by default (SAMME.R)\n",
    "ads=AdaBoostClassifier(base_estimator=svc,n_estimators=50,algorithm='SAMME')\n",
    "ads=AdaBoostClassifier()\n",
    "ads.fit(x_train,y_train)\n",
    "predads=et.predict(x_test)\n",
    "print(accuracy_score(y_test,predads))\n",
    "print(confusion_matrix(y_test,predads))\n",
    "print(classification_report(y_test,predads))\n",
    "\n",
    "\n",
    "svc=SVC(probability=True,kernel='linear')\n",
    "adsl=AdaBoostClassifier(base_estimator=svc,n_estimators=50)\n",
    "adsl=AdaBoostClassifier()\n",
    "adsl.fit(x_train,y_train)\n",
    "predadsl=et.predict(x_test)\n",
    "print(accuracy_score(y_test,predadsl))\n",
    "print(confusion_matrix(y_test,predadsl))\n",
    "print(classification_report(y_test,predadsl))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd39ac56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98\n",
      "[[19  0  0]\n",
      " [ 0 15  0]\n",
      " [ 0  1 15]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       0.94      1.00      0.97        15\n",
      "           2       1.00      0.94      0.97        16\n",
      "\n",
      "    accuracy                           0.98        50\n",
      "   macro avg       0.98      0.98      0.98        50\n",
      "weighted avg       0.98      0.98      0.98        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gb=GradientBoostingClassifier()\n",
    "gb.fit(x_train,y_train)\n",
    "predgb=gb.predict(x_test)\n",
    "print(accuracy_score(y_test,predgb))\n",
    "print(confusion_matrix(y_test,predgb))\n",
    "print(classification_report(y_test,predgb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7ff188",
   "metadata": {},
   "source": [
    "# Voting Classifier\n",
    "2 types of Voting Classifier\n",
    "1.hard voting\n",
    "2.soft voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d4168f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('LR', KNeighborsClassifier()),\n",
       " ('SVC', SVC(gamma='auto', probability=True)),\n",
       " ('DTC', DecisionTreeClassifier())]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "estimator=[]\n",
    "estimator.append(('LR',KNeighborsClassifier()))\n",
    "estimator.append(('SVC',SVC(gamma='auto',probability=True)))\n",
    "estimator.append(('DTC',DecisionTreeClassifier()))\n",
    "# here create the list and inside it pass different algorithe\n",
    "estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4a4442",
   "metadata": {},
   "source": [
    "# Hard Voting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66628b20",
   "metadata": {},
   "source": [
    "# voting classifier with hard voting\n",
    "vot_hard=VotingClassifier(estimators=estimator,voting='hard')\n",
    "vot_hard.fit(x_train,y_train)\n",
    "vh_pred=vot_hard.predict(x_test)\n",
    "print(vh_pred)\n",
    "#using accuracy_score metric to predict accuracy\n",
    "score=accuracy_score(y_test,vh_pred)\n",
    "print(\"hard voting score %d\" %score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7f4915",
   "metadata": {},
   "source": [
    "# Soft voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "631af633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0 0 0 1 0 0 2 1\n",
      " 0 0 0 2 1 1 0 0 1 2 2 1 2]\n",
      "soft voting score  1\n"
     ]
    }
   ],
   "source": [
    "vot_soft=VotingClassifier(estimators=estimator,voting='soft')\n",
    "vot_soft.fit(x_train,y_train)\n",
    "sv_pred=vot_soft.predict(x_test)\n",
    "print(sv_pred)\n",
    "#using accuracy_score metric to predict accuracy\n",
    "svscore=accuracy_score(y_test,sv_pred)\n",
    "print(\"soft voting score % d\" %svscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b88e2c",
   "metadata": {},
   "source": [
    "# Hyper perameter tunning\n",
    "#its use with GridSearchCV algo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "052c2f61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kernel': ['rbf', 'poly', 'linear'], 'C': [1, 10]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm,datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "iris=datasets.load_iris()\n",
    "#dict1 is parameter\n",
    "dict1={'kernel':['rbf','poly','linear'],'C':[1,10]}\n",
    "#here call the values into the list mode\n",
    "dict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86159774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [1, 10], &#x27;kernel&#x27;: [&#x27;rbf&#x27;, &#x27;poly&#x27;, &#x27;linear&#x27;]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [1, 10], &#x27;kernel&#x27;: [&#x27;rbf&#x27;, &#x27;poly&#x27;, &#x27;linear&#x27;]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [1, 10], 'kernel': ['rbf', 'poly', 'linear']})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc=svm.SVC()\n",
    "gridcv=GridSearchCV(svc,dict1)\n",
    "gridcv.fit(iris.data,iris.target)\n",
    "gridcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f5d33df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'kernel': 'poly'}\n"
     ]
    }
   ],
   "source": [
    "# here its give the best perameter\n",
    "print(gridcv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "812398f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99\n"
     ]
    }
   ],
   "source": [
    "#here we can use best parameter which we find by GridSearchcv\n",
    "sv=svm.SVC(kernel='linear',C=1)\n",
    "sv.fit(iris.data,iris.target)\n",
    "t=sv.score(iris.data,iris.target)\n",
    "print(round(t,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af55fd68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini'}\n",
      "0.9666666666666668\n",
      "0.97\n"
     ]
    }
   ],
   "source": [
    "#now use for DecisionTreeClassifier\n",
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "dtc=DecisionTreeClassifier()\n",
    "iris=datasets.load_iris()\n",
    "grid_param={'criterion':['gini','entropy']}\n",
    "grid_param\n",
    "\n",
    "gd_sr=GridSearchCV(estimator=dtc,param_grid=grid_param,scoring='accuracy',cv=5)\n",
    "\n",
    "gd_sr.fit(iris.data,iris.target)\n",
    "\n",
    "best_parameters=gd_sr.best_params_\n",
    "print(best_parameters)\n",
    "best_result=gd_sr.best_score_\n",
    "print(best_result)\n",
    "print(round(best_result,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26fb235c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now take best parameter into original\n",
    "dtc=DecisionTreeClassifier(criterion='gini')\n",
    "dtc.fit(iris.data,iris.target)\n",
    "dtc.score(iris.data,iris.target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1a34923",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gridSearch for algorithm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e795c41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(estimator=Ridge(),\n",
      "             param_grid={'alpha': [1, 0.1, 0.001, 0.0001, 0]})\n",
      "0.4823214545225419\n",
      "0.0001\n",
      "{'alpha': 0.0001}\n"
     ]
    }
   ],
   "source": [
    "# load dibetes dataset\n",
    "dataset=datasets.load_diabetes()\n",
    "#prepare the range of alpha values to test\n",
    "#alphas=np.array([1,0.1,0.001,0.0001,0])\n",
    "alphavalues={'alpha':[1,0.1,0.001,0.0001,0]}\n",
    "#creat and fit a ridge regression model and testing each alpha\n",
    "model=Ridge()\n",
    "#grid=GridSearchCV(estimator=model, param_grid=dictionary(alphas values)\n",
    "grid=GridSearchCV(estimator=model, param_grid=alphavalues)\n",
    "grid.fit(dataset.data,dataset.target)\n",
    "print(grid)\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_.alpha)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69cadf03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.5177484222203498\n",
      "[  -9.9599668  -239.73847277  519.90790158  324.3246984  -783.36095429\n",
      "  469.74463276   97.14958563  176.00307904  747.93105798   67.67944396]\n",
      "score: 0.5177479163759708\n"
     ]
    }
   ],
   "source": [
    "ds=datasets.load_diabetes()\n",
    "x=ds.data\n",
    "y=ds.target\n",
    "lr=LinearRegression()\n",
    "lr.fit(x,y)\n",
    "print('score:',lr.score(x,y))\n",
    "\n",
    "rd=Ridge(alpha=0.0001)\n",
    "rd.fit(x,y)\n",
    "print(rd.coef_)\n",
    "print('score:',rd.score(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2292d9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  -9.9599668  -239.73847277  519.90790158  324.3246984  -783.36095429\n",
      "  469.74463276   97.14958563  176.00307904  747.93105798   67.67944396]\n",
      "score: 0.5177479163759708\n"
     ]
    }
   ],
   "source": [
    "rd=Ridge(alpha=0.0001)\n",
    "rd.fit(dataset.data,dataset.target)\n",
    "print(rd.coef_)\n",
    "print('score:',rd.score(dataset.data,dataset.target))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ddab23",
   "metadata": {},
   "source": [
    "# ramndomized search for algorithm tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e9fb706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV(estimator=Ridge(),\n",
      "                   param_distributions={'alpha': [1, 0.1, 0.001, 0.0001, 0]})\n",
      "0.4823214545225419\n",
      "0.0001\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "# load dibetes dataset\n",
    "dataset=datasets.load_diabetes()\n",
    "#prepare a uniform distributionto sample for a alpha parameter\n",
    "param_grid={'alpha':[1,0.1,0.001,0.0001,0]}\n",
    "\n",
    "#creat and fit a ridge regression model and testing random aplha values\n",
    "model=Ridge()\n",
    "rsearch=RandomizedSearchCV(estimator=model,param_distributions=param_grid)\n",
    "rsearch.fit(dataset.data,dataset.target)\n",
    "print(rsearch)\n",
    "#summarized the result of the ramdom parameters search\n",
    "print(rsearch.best_score_)\n",
    "print(rsearch.best_estimator_.alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4df71a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98f589b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772b7344",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
